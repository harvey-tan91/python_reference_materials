{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pandas Functions***\n",
    "======================\n",
    "* pd.util.testing.makeDataFrame() --- create a random DataFrame\n",
    "\n",
    "*Notebook Settings*\n",
    "-------------------\n",
    "* pd.set_option('max_rows', 10) --- set 10 to be the maximum number of rows to be displayed\n",
    "    * For reference, see \n",
    "        * < https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html > \n",
    "        * < https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html >\n",
    "\n",
    "***DataFrame Methods & Functions***\n",
    "===================================\n",
    "\n",
    "*General Notes*\n",
    "---------------\n",
    "* When producing calculated columns with input columns with missing values, the output column will be blank if one of the input columns is blank\n",
    "* For text or category values, might be efficient to change the datatype to 'category'\n",
    "* Internal Representation of Dataframe\n",
    "    ![Example](https://www.dataquest.io/wp-content/uploads/2019/01/df_blocks.png)\n",
    "\n",
    "*Reading Files*\n",
    "---------------\n",
    "* pd.read_csv(..., parse_dates=[0], chunksize=25]) --- read csv file\n",
    "\n",
    "*Descriptive Functions*\n",
    "-----------------------\n",
    "* df.describe() --- return the columns' statistics\n",
    "* df.info() --- return high level summary of the columns\n",
    "* df.shape --- return the rows and columns\n",
    "* df.size --- return the total number of possible values (nrows * ncols)\n",
    "* df.count() --- return the number of non-zero items in each column\n",
    "* df.hist(fig_size=...) --- return the histogram of all numerical attributes\n",
    "* df.corr() --- return the correlation matrix\n",
    "\n",
    "*Time-series Functions*\n",
    "-----------------------\n",
    "* df.X1.resample('1y').median() --- to convert higher frequency data to lower frequency data based on some aggregation method\n",
    "* df.X1.diff(1) --- to take the first order difference\n",
    "* df.X1.rolling(5).mean()\n",
    "* pd.plotting.autocorrelation_plot(data.X1\n",
    "\n",
    "*Date Related Function*\n",
    "-----------------------\n",
    "* pd.date_range('01 Jan 2021', '31 DDec 2021', freq='M', period=int) --- create a series of datetime values\n",
    "* pd.to_datetime(x) --- to convert the column to datetime datatype\n",
    "* pd.DateOffset(n=1, months=1)\n",
    "\n",
    "\n",
    "*Data Retrival Functions*\n",
    "-------------------------\n",
    "* df.loc[ a:b, [x,y,z] ] --- retrieve data from defined label index\n",
    "* df[ (df.X1 == 'abc') &| (df.X2 == 'def') ] --- retrieve data based on defined conditions\n",
    "* df.X1.isin(['abc'])\n",
    "* df.X1.str.contains( 'abc|def', case=True, na=False ) --- to filter data that contain certain string characters\n",
    "    * case = False to ignore the characters' case\n",
    " * df.select_dtypes(include=[['datetime', 'object']], exclude=[['float']]) --- to include/exclude columns of defined datatypes\n",
    "* df.isnull() --- return a DataFrame with Boolean values testing if cell is na\n",
    "* df.sample(frac=0.5) --- randomly return 50% of the data\n",
    "* df.nlargest(10, 'X1') --- return the top 10 rows based on X1\n",
    "* df.X1.value_counts() --- return the frequency count of the values in X1\n",
    "* df.duplicated(keep=False) --- return a Boolean series where ALL occurrence of duplicated records will display True\n",
    "* df.X1.between(10,20) --- return Boolean series for values that fall between defined values\n",
    "\n",
    "*Information Retrival Function*\n",
    "-------------------------------\n",
    "* df.index --- to return the index method\n",
    "* df.memory_usage(deep=True) --- if deep=True, it will retrieve the true memory usage for string/object datatype else it will retrieve the size of the pointer\n",
    "\n",
    "*Data Manipulation Functions*\n",
    "-----------------------------\n",
    "* df.applymap(some_function) --- to apply some function to all elements in the table\n",
    "* df['X1'].apply(some_function, axis=0) --- to apply some function at the row level\n",
    "* df.rename(columns= {'col1': 'column1'}, inplace=True) --- to rename the columns\n",
    "* df.X1.dt.year --- X1 is datetime obj, dt is datetime library\n",
    "* df.explode('X1') --- expand list in cell into row items\n",
    "* df['X1'].pct_change() --- generate series of percentage change \n",
    "* df.sort_values(by=['...'], ascending=False, inplace=False)\n",
    "* df['X1'].astype(str) --- change the column datatype to string\n",
    "* df.fillna(999) --- fill na values with 999\n",
    "* df.fillna(method = 'bfill') --- this fill na values with the last known values\n",
    "* df.X1.replace( {'values_2b_replaced': 'replacement_value', }, inplace= True ) --- to replace values \n",
    "    * df.replace( '[A-Za-z]', '', regex= True) --- to replace all alphabetical into blank\n",
    "* df.X1.where( df.X1 > condition, replacement_values, inplace= True) --- replace values if fufill certain conditions\n",
    "* df.X1.str.split('-', expand= True) --- delimit the strategy by '-' into columns\n",
    "* df.values --- generate a 2D numpy array\n",
    "* df.melt(id_vars, var_name, value_name) --- unpivot the table\n",
    "    * id_vars --- list of columns to keeep\n",
    "    * var_name --- list of columns to unpivot\n",
    "    * value_name --- name of the value column if you want to rename\n",
    "###\n",
    "* pd.factorize(data.X1) --- to encode the values\n",
    "* pd.cut(df.X1, bins, labels) --- to segment the values into defined bins\n",
    "\n",
    "\n",
    "*Drop Functions*\n",
    "----------------\n",
    "* df.drop([['col1']], axis=1, inplace=True) --- remove column if axis=1\n",
    "* df.dropna(axis=0, thresh=4, inplace=False) --- require at least 4 non-NA items otherwise remove row, use subset parameter if targeting specific column\n",
    "* df.drop_duplicates(keep=False, ignore_index=True) --- if keep=False, drop all duplicates, if keep=first, drop first duplicate occurrence\n",
    "\n",
    "*Aggregation, Appending & Joining*\n",
    "----------------------------------\n",
    "* df.groupby('X1')['X2'].mean() --- to group the data\n",
    "* df.groupby(['X1','X2'])['X3','X4'].mean()\n",
    "* df.groupby('X1').agg( {'X2': 'mean', 'X3': np.count_nonzero} ).rename(columns= {'X2': 'XX2', 'X3': 'XX3'} ).reset_index().round()\n",
    "* df.groupby('X1').X2.transform(some_function)\n",
    "###\n",
    "* pd.crosstab(df.X1, df.X2, margin=True) --- create a frequency distrubtion table\n",
    "* pd.crosstab(df.X1, df.X2, values= df.X3, aggfunc=np.mean)\n",
    "###\n",
    "* pd.concat( [df1, df2], ignore_index=False, axis=0, join='outer')\n",
    "* df1.append(df2)\n",
    "###\n",
    "* df1.merge(df2, left_on= df1.keyA, right_on= df2.keyA, how= {'right', 'left', 'inner','outer'} )\n",
    "* pd.merge(df1, df2, left_on= df1.keyA, right_on= df2.keyA, how= {'right', 'left', 'inner','outer'})\n",
    "\n",
    "*Export Data*\n",
    "-------------\n",
    "* df.to_excel('output.xlsx', index= False)\n",
    "* df.to_csv('output.csv', index= False)\n",
    "\n",
    "---\n",
    "***Pandas Series Methods & Functions***\n",
    "=======================================\n",
    "\n",
    "*Descriptive Functions*\n",
    "-----------------------\n",
    "* s.value_counts(normalize=False) --- return the count of values\n",
    "\n",
    "*Information Retrival Function*\n",
    "-------------------------------\n",
    "* s.unique() --- return the distinct values\n",
    "* s.nunique() --- return the number of distinct values\n",
    "\n",
    "*Data Manipulation Functions*\n",
    "-----------------------------\n",
    "* s.to_frame() --- convert series to DataFrame\n",
    "---\n",
    "\n",
    "***DASK DataFrame***\n",
    "====================\n",
    "```import dask.dataframe as dd```\n",
    "* DASK split the data into partitions\n",
    "###\n",
    "###\n",
    "*DASK Methods*\n",
    "-------------\n",
    "* dd.read_csv()\n",
    "\n",
    "*DataFrame Methods Relatedd to DASK*\n",
    "------------------------------------\n",
    "* df.partitions[0].compute()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***END***\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb8f35743f9001c30e3bbd777425f7e52a39aada76c3a9d7849db12bd416f99c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
