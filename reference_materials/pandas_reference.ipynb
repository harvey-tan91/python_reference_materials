{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Pandas Functions***\r\n",
    "======================\r\n",
    "* pd.util.testing.makeDataFrame() --- create a random DataFrame\r\n",
    "\r\n",
    "*Notebook Settings*\r\n",
    "-------------------\r\n",
    "* pd.set_option('max_rows', 10) --- set 10 to be the maximum number of rows to be displayed\r\n",
    "    * For reference, see \r\n",
    "        * < https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html > \r\n",
    "        * < https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html >\r\n",
    "\r\n",
    "***DataFrame Methods & Functions***\r\n",
    "===================================\r\n",
    "\r\n",
    "*General Notes*\r\n",
    "---------------\r\n",
    "* When producing calculated columns with input columns with missing values, the output column will be blank if one of the input columns is blank\r\n",
    "* For text or category values, might be efficient to change the datatype to 'category'\r\n",
    "\r\n",
    "*Reading Files*\r\n",
    "---------------\r\n",
    "* pd.read_csv(..., parse_dates=[0], chunksize=25]) --- read csv file\r\n",
    "\r\n",
    "*Descriptive Functions*\r\n",
    "-----------------------\r\n",
    "* df.describe() --- return the columns' statistics\r\n",
    "* df.info() --- return high level summary of the columns\r\n",
    "* df.shape --- return the rows and columns\r\n",
    "* df.size --- return the total number of possible values (nrows * ncols)\r\n",
    "* df.count() --- return the number of non-zero items in each column\r\n",
    "* df.hist(fig_size=...) --- return the histogram of all numerical attributes\r\n",
    "* df.corr() --- return the correlation matrix\r\n",
    "\r\n",
    "*Time-series Functions*\r\n",
    "-----------------------\r\n",
    "* df.X1.resample('1y').median() --- to convert higher frequency data to lower frequency data based on some aggregation method\r\n",
    "* df.X1.diff(1) --- to take the first order difference\r\n",
    "* df.X1.rolling(5).mean()\r\n",
    "* pd.plotting.autocorrelation_plot(data.X1)\r\n",
    "* pd.date_range('01 Jan 2021', '31 DDec 2021', freq='M', period=int) --- create a series of datetime values\r\n",
    "    * pd.DateOffset(days=10) --- create an offset datetime object\r\n",
    "\r\n",
    "*Data Retrival Functions*\r\n",
    "-------------------------\r\n",
    "* df.loc[ a:b, [x,y,z] ] --- retrieve data from defined label index\r\n",
    "* df[ (df.X1 == 'abc') &| (df.X2 == 'def') ] --- retrieve data based on defined conditions\r\n",
    "* df.X1.isin(['abc'])\r\n",
    "* df.X1.str.contains( 'abc|def', case=True, na=False ) --- to filter data that contain certain string characters\r\n",
    "    * case = False to ignore the characters' case\r\n",
    " * df.select_dtypes(include=[['datetime', 'object']], exclude=[['float']]) --- to include/exclude columns of defined datatypes\r\n",
    "* df.isnull() --- return a DataFrame with Boolean values testing if cell is na\r\n",
    "* df.sample(frac=0.5) --- randomly return 50% of the data\r\n",
    "* df.nlargest(10, 'X1') --- return the top 10 rows based on X1\r\n",
    "* df.X1.value_counts() --- return the frequency count of the values in X1\r\n",
    "* df.duplicated(keep=False) --- return a Boolean series where ALL occurrence of duplicated records will display True\r\n",
    "* df.X1.between(10,20) --- return Boolean series for values that fall between defined values\r\n",
    "\r\n",
    "*Information Retrival Function*\r\n",
    "-------------------------------\r\n",
    "* df.index --- to return the index method\r\n",
    "* df.memory_usage(deep=True) --- if deep=True, it will retrieve the true memory usage for string/object datatype else it will retrieve the size of the pointer\r\n",
    "\r\n",
    "*Data Manipulation Functions*\r\n",
    "-----------------------------\r\n",
    "* df.applymap(some_function) --- to apply some function to all elements in the table\r\n",
    "* df['X1'].apply(some_function, axis=0) --- to apply some function at the row level\r\n",
    "* df.rename(columns= {'col1': 'column1'}, inplace=True) --- to rename the columns\r\n",
    "* df.X1.dt.year --- X1 is datetime obj, dt is datetime library\r\n",
    "* df.explode('X1') --- expand list in cell into row items\r\n",
    "* df['X1'].pct_change() --- generate series of percentage change \r\n",
    "* df.sort_values(by=['...'], ascending=False, inplace=False)\r\n",
    "* df['X1'].astype(str) --- change the column datatype to string\r\n",
    "* df.fillna(999) --- fill na values with 999\r\n",
    "* df.fillna(method = 'bfill') --- this fill na values with the last known values\r\n",
    "* df.X1.replace( {'values_2b_replaced': 'replacement_value', }, inplace= True ) --- to replace values \r\n",
    "    * df.replace( '[A-Za-z]', '', regex= True) --- to replace all alphabetical into blank\r\n",
    "* df.X1.where( df.X1 > condition, replacement_values, inplace= True) --- replace values if fufill certain conditions\r\n",
    "* df.X1.str.split('-', expand= True) --- delimit the strategy by '-' into columns\r\n",
    "* df.values --- generate a 2D numpy array\r\n",
    "* df.melt(id_vars, var_name, value_name) --- unpivot the table\r\n",
    "    * id_vars --- list of columns to keeep\r\n",
    "    * var_name --- list of columns to unpivot\r\n",
    "    * value_name --- name of the value column if you want to rename\r\n",
    "###\r\n",
    "* pd.to_datetime(x) --- to convert the column to datetime datatype\r\n",
    "* pd.factorize(data.X1) --- to encode the values\r\n",
    "* pd.cut(df.X1, bins, labels) --- to segment the values into defined bins\r\n",
    "\r\n",
    "*Drop Functions*\r\n",
    "----------------\r\n",
    "* df.drop([['col1']], axis=1, inplace=True) --- remove column if axis=1\r\n",
    "* df.dropna(axis=0, thresh=4, inplace=False) --- require at least 4 non-NA items otherwise remove row, use subset parameter if targeting specific column\r\n",
    "* df.drop_duplicates(keep=False, ignore_index=True) --- if keep=False, drop all duplicates, if keep=first, drop first duplicate occurrence\r\n",
    "\r\n",
    "*Aggregation, Appending & Joining*\r\n",
    "----------------------------------\r\n",
    "* df.groupby('X1')['X2'].mean() --- to group the data\r\n",
    "* df.groupby(['X1','X2'])['X3','X4'].mean()\r\n",
    "* df.groupby('X1').agg( {'X2': 'mean', 'X3': np.count_nonzero} ).rename(columns= {'X2': 'XX2', 'X3': 'XX3'} ).reset_index().round()\r\n",
    "* df.groupby('X1').X2.transform(some_function)\r\n",
    "###\r\n",
    "* pd.crosstab(df.X1, df.X2, margin=True) --- create a frequency distrubtion table\r\n",
    "* pd.crosstab(df.X1, df.X2, values= df.X3, aggfunc=np.mean)\r\n",
    "###\r\n",
    "* pd.concat( [df1, df2], ignore_index=False, axis=0, join='outer')\r\n",
    "* df1.append(df2)\r\n",
    "###\r\n",
    "* df1.merge(df2, left_on= df1.keyA, right_on= df2.keyA, how= {'right', 'left', 'inner','outer'} )\r\n",
    "* pd.merge(df1, df2, left_on= df1.keyA, right_on= df2.keyA, how= {'right', 'left', 'inner','outer'})\r\n",
    "\r\n",
    "*Export Data*\r\n",
    "-------------\r\n",
    "df.to_excel('output.xlsx', index= False)\r\n",
    "df.to_csv('output.csv', index= False)\r\n",
    "\r\n",
    "---\r\n",
    "***Pandas Series Methods & Functions***\r\n",
    "=======================================\r\n",
    "\r\n",
    "*Descriptive Functions*\r\n",
    "-----------------------\r\n",
    "* s.value_counts(normalize=False) --- return the count of values\r\n",
    "\r\n",
    "*Information Retrival Function*\r\n",
    "-------------------------------\r\n",
    "* s.unique() --- return the distinct values\r\n",
    "* s.nunique() --- return the number of distinct values\r\n",
    "\r\n",
    "*Data Manipulation Functions*\r\n",
    "-----------------------------\r\n",
    "* s.to_frame() --- convert series to DataFrame\r\n",
    "---\r\n",
    "\r\n",
    "***DASK DataFrame***\r\n",
    "====================\r\n",
    "```import dask.dataframe as dd```\r\n",
    "* DASK split the data into partitions\r\n",
    "###\r\n",
    "###\r\n",
    "*DASK Methods*\r\n",
    "-------------\r\n",
    "* dd.read_csv()\r\n",
    "\r\n",
    "***END***\r\n",
    "========="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb8f35743f9001c30e3bbd777425f7e52a39aada76c3a9d7849db12bd416f99c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}